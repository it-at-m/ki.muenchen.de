[<v-icon>mdi-arrow-left</v-icon> Zur√ºck zum Blog](/blog/index.md)

# Unser Open Source Stack f√ºr den souver√§nen Betrieb von KI-Anwendungen

Seit der Ver√∂ffentlichung von `ChatGPT` haben generative KI-Modelle enorm an Bedeutung gewonnen. Gleichzeitig wurde die Evolution eines ganzen √ñkosystems an Werkzeugen vorangetrieben, die die F√§higkeiten der Modelle einfacher und sicherer nutzbar machten.
Anfangs stand dabei oft nur eine Benutzeroberfl√§che zum einfachen Chatten mit den gro√üen Sprachmodellen im Fokus. Inzwischen arbeiten viele daran, KI tief in ihre Systeme zu integrieren und mithilfe von KI-Agenten Workflows zu orchestrieren.

Um diese komplexen Systeme im Enterprise-Umfeld korrekt und nachvollziehbar bereitzustellen, sind zahlreiche Funktionalit√§ten erforderlich.
Neben Start-ups mit SaaS-L√∂sungen und Hyperscalern mit End-to-End-Systemen k√∂nnen diese auch mithilfe von Open-Source-Software-Komponenten (OSS) abgedeckt werden. OSS wahrt dabei die digitale Souver√§nit√§t und hilft gleichzeitig, Kosten zu sparen.

Welchen Softwarestack das [KI Competence Center](/kicc) (KICC) der Stadt M√ºnchen f√ºr die st√§dtischen KI-Systeme bereitstellt, erkl√§ren wir in diesem Artikel.

## Motivation: GenAI wird immer komplexer

Generative KI ist ein sehr dynamisches Feld, in dem sich Technologien und Methoden rasant weiterentwickeln.
Am Anfang dieser Entwicklung waren die Systeme noch einfache Wrapper, die Sprachmodelle mittels Webanwendungen zug√§nglich machten.

![Primitives GenAI System](/img/blog/genai.png){.light-only}
![Primitives GenAI System](/img/blog/genai_dark.png){.dark-only}

> Primitives GenAI System; Quelle: Eigene Darstellung

Mit der Zeit kommen jedoch immer mehr Anforderungen hinzu, um ein vollwertiges KI-System zu betreiben.
Ausl√∂ser hierf√ºr sind nicht nur steigende Anforderungen von Nutzer\*innen, sondern auch neue technische M√∂glichkeiten, rechtliche Anforderungen (AI Act) und die zunehmende Integration generativer KI mit Bestands-Systemen.

![√úberblick √ºber Anforderungen und m√∂gliche Anbieter](/img/blog/swirlai-vendor-landscape.png)

> √úberblick √ºber Anforderungen und m√∂gliche Anbieter, Quelle: [SwirlAI Newsletter](https://www.newsletter.swirlai.com/p/enterprise-agentic-ai-hierarchy-of)

Die wichtigsten Bestandteile, die in einem modernen GenAI-System ben√∂tigt werden, sind:

- **Anwendungslogik und Orchestrierung**: Standardisierte Frameworks und darin integrierte Abl√§ufe, die √ºber einzelne Anbieter hinweg m√∂glichst einheitlich und deterministisch sind.
- **KI-Modelle**: Gro√üe Sprachmodelle (LLMs), Embedding-Modelle und andere spezialisierte Modelle, die im besten Fall √ºber eine standardisierte Schnittstelle (API) aus dem gesamten Unternehmen heraus angesprochen werden k√∂nnen.
- **Nachvollziehbarkeit & Evaluation**: Der Ablauf und sowie die Ein- und Ausgaben der KI-Systeme m√ºssen zur Sicherstellung der Nachvollziehbarkeit protokolliert und evaluiert werden.
- **Persistenz**: Speicherung von Dokumenten zugeh√∂rigen Suchvektoren (Embeddings) von Dokumenten
- **Einlesen von Dokumenten**: Extraktion von Informationen aus verschiedenen Dateiformaten (z.B. PDFs, Word-Dokumente) und deren Umwandlung in ein f√ºr die KI verst√§ndliches Format.
- **Websuche**: Integration von Websuchfunktionen zur Anreicherung der KI-Modelle mit aktuellen Informationen

Weitere m√∂gliche Bestandteile, die in diesem Artikel **nicht** betrachtet werden:

- **MCP-Registry**: [Das Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) ist ein Protokoll, das den Zugriff auf Anwendungen mittels Sprachmodellen standardisiert. Eine MCP-Registry b√ºndelt den Zugriff auf eine Vielzahl von MCP-Services.
- **Persistenz f√ºr Graphen**: Mithilfe von Sprachmodellen k√∂nnen auch die Beziehungen von Entit√§ten in Texten extrahiert und in strukturierter Form als Graphen abgebildet werden. Anschlie√üend k√∂nnen die extrahierten Graphen f√ºr Suchen und Analysen genutzt werden..

Ein √úberblick √ºber m√∂gliche Komponenten ( von uns verwendete Komponenten in üü©), sowohl Open Source, als auch in ist in folgender Grafik zu finden.

![Auswahl m√∂glicher Komponenten](/img/blog/genai-component-map.png){.light-only}
![Auswahl m√∂glicher Komponenten](/img/blog/genai-component-map_dark.png){.dark-only}

> Auswahl m√∂glicher Komponenten, Quelle: Eigene Darstellung

## Der M√ºnchner Open Source GenAI Stack

Um die digitale Souver√§nit√§t der Stadt M√ºnchen zu wahren und gleichzeitig die Kosten im Rahmen zu halten, haben wir uns bewusst f√ºr einen Open-Source-Software-Stack entschieden.

Die einzelnen Komponenten des Stacks sind aufeinander abgestimmt und erm√∂glichen eine nahtlose Integration. Zentrale Komponenten stellen wir f√ºr all unsere KI-Systeme bereit, sowohl f√ºr Eigenentwicklungen als auch f√ºr Kaufsoftware.
Unsere Eigenentwicklungen nutzen eine Open-Source-LLM-Orchestrierungssoftware und verwalten ihre Daten jeweils selbst.

![M√ºnchner Open Source GenAI Stack](/img/blog/kicc-muc-stack.png){.light-only}
![M√ºnchner Open Source GenAI Stack](/img/blog/kicc-muc-stack_dark.png){.dark-only}

> M√ºnchner Open Source GenAI Stack, Quelle: Eigene Darstellung

### üéº Logik & Orchestrierung: [LangChain](https://github.com/langchain-ai/langchain) & [LangGraph](https://github.com/langchain-ai/langgraph)

Um die Abh√§ngigkeit von der API eines bestimmten Modellanbieters zu umgehen, kann der Modellzugriff mithilfe eines LLM-Integration-Frameworks wie LangChain abstrahiert werden. Das Gleiche trifft auch auf weitere Komponenten wie Vektordatenbanken zu.
Dar√ºber hinaus vereinfacht `LangChain` die Abbildung sequenzieller Workflows mit Sprachmodellen.

`LangGraph` erweitert dieses Konzept f√ºr autonome Agenten, indem Workflows nun auf Graphen basieren.

- `LangChain` setzen wir in der [KI-Suche im Dienstleistungsfinder](/ki-systeme/dl) ein.
- `LangGraph` setzen wir in [MUCGPT](/ki-systeme/mucgpt) ein.

### üíæ Persistenz: [Qdrant](https://qdrant.tech/), [pgvector](https://github.com/pgvector/pgvector) & [Valkey](https://valkey.io/)

Um in einem Sprachmodell auf eigene Daten zugreifen zu k√∂nnen, m√ºssen diese in den Kontext des Sprachmodells eingef√ºgt werden. Falls mehr Daten vorhanden sind als Platz, m√ºssen diese zun√§chst sinnvoll ausgew√§hlt werden. Hierf√ºr hat sich die Technik Retrieval Augmented Generation (RAG) etabliert, die die Auswahl der Daten mittels einer Suche trifft ([Funktionsweise am Beispiel DLF](/ki-systeme/dlf#funktionsweise)).

Zuvor werden die Daten in vektorisierter Form in einer Vektordatenbank abgelegt. `Pgvektor` erweitert die OSS-Datenbank `Postgres` um diese F√§higkeiten.
Wir setzen jedoch vor allem auf die Open-Source-Vektordatenbank Qdrant.
Qdrant erm√∂glicht eine performante Suche und Filterung von Vektordaten. Zudem nutzen wir die hybride Suchfunktion, die die Kombination von Embedding-basierter Suche und klassischer Stichwortsuche erm√∂glicht.

`Valkey` ist ein Hochleistungs-Key/Value-Store, den wir vor allem zur Zwischenspeicherung kurzfristiger Informationen nutzen. Beispielsweise k√∂nnen damit die Zust√§nde eines Agentensystems zwischengespeichert werden.

### üß† KI-Modellzugriff: [LiteLLM](https://www.litellm.ai/)

`LiteLLM` ist ein API-Gateway f√ºr Sprachmodelle. Es erm√∂glicht die Anbindung verschiedener Modellprovider wie Azure hinter einer gemeinsamen API. Dadurch ist es m√∂glich, ohne gro√üen Aufwand zu einem anderen Anbieter zu wechseln. Als Organisation k√∂nnen wir uns an dieser zentralen Stelle um den Modellzyklus k√ºmmern und so einen Wildwuchs innerhalb unserer Organisation verhindern.

Nutzer k√∂nnen einfach virtuelle API-Keys f√ºr bestimmte Modelle zugewiesen bekommen. Dies erlaubt das schnelle Ausprobieren von Prototypen. Zus√§tzlich k√∂nnen Budgets und Ratelimits festgelegt werden.

### üîé Nachvollziehbarkeit & Evaluation: [Langfuse](https://langfuse.com/)

`Langfuse` ist eine Komponente zur Evaluierung von Sprachmodell Anwendungen. Zwischenschritte in der Logik von KI-Anwendungen k√∂nnen damit nachvollziehbar gespeichert werden. Au√üerdem k√∂nnen Ergebnisse entweder mit Nutzerfeedback oder mittels KI basierter Evaluatoren bewertet werden. So l√§sst sich quantitativ nachvollziehen, wie gut eine bestimmte Version des Systems funktioniert.

F√ºr die Entwicklung nutzen wir zus√§tzlich Datens√§tze, auf denen einzelne Evaluierungsl√§ufe durchgef√ºhrt werden k√∂nnen. Wir nutzen dies beispielsweise, um die Effizienz des Retrievals mit unterschiedlichen Embeddingmodellen zu ermitteln.

Dar√ºber hinaus nutzen wir `Langfuse` f√ºr die Versionierung und das Speichern von Prompts.

### üìÉ Dokumenten-Parsing: [Docling](https://docling-project.github.io/docling/)

`Docling` ist ein Open-Source-Tool zur Extraktion und Strukturierung von Informationen aus unterschiedlichen Dokumentenformaten wie PDF, Word oder HTML. In GenAI-Systemen ist es essenziell, Inhalte aus verschiedensten Quellen automatisiert und zuverl√§ssig in ein maschinenlesbares Format zu √ºberf√ºhren. Nur so k√∂nnen die Daten effizient vektorisiert, durchsucht und f√ºr KI-Anwendungen nutzbar gemacht werden. `Docling` unterst√ºtzt dabei, Metadaten und Textinhalte sauber zu extrahieren und erm√∂glicht so eine konsistente Weiterverarbeitung in angeschlossenen KI-Systemen.

### üåè Websuche: [SearXNG](https://github.com/searxng/searxng)

`SearXNG` ist eine Open-Source-Metasuchmaschine, die Suchanfragen an verschiedene Anbieter weiterleitet und die Ergebnisse aggregiert. Damit l√§sst sich Websuche datenschutzfreundlich und unabh√§ngig von gro√üen Suchmaschinen in eigene Systeme integrieren. Im Rahmen unseres GenAI-Stacks planen wir, `SearXNG` einzusetzen, um aktuelle Webinformationen f√ºr KI-Anwendungen bereitzustellen ‚Äì etwa f√ºr RAG-Szenarien. Ein Vorteil: Durch die direkte Abfrage aktueller Daten entf√§llt das aufw√§ndige Parsen und Speichern gro√üer Datenmengen als Embeddings in einer Vektordatenbank.

## Fazit

Der M√ºnchner Open Source GenAI Stack bietet eine flexible und kosteneffiziente L√∂sung f√ºr die Herausforderungen der generativen KI im Enterprise-Bereich.
Durch den Einsatz bew√§hrter OSS-Projekte kann die Stadt M√ºnchen ihre digitale Souver√§nit√§t wahren und gleichzeitig innovative KI-Anwendungen entwickeln.

Die verschiedenen Komponenten des Stacks erm√∂glichen eine nahtlose Integration und Orchestrierung von KI-Systemen, die f√ºr die spezifischen Anforderungen der Stadt angepasst sind.
So wird sichergestellt, dass die st√§dtischen KI-Systeme nicht nur leistungsf√§hig, sondern auch transparent und nachvollziehbar sind.

[<v-icon>mdi-arrow-left</v-icon> Zur√ºck zum Blog](/blog/index.md)
